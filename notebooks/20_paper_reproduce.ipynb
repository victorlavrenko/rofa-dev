{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Setup\n",
        "# If running in Colab, install the package first:\n",
        "# !git clone https://github.com/victorlavrenko/rofa\n",
        "# %cd rofa\n",
        "# %pip install -e .\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from rofa import analysis\n",
        "from rofa.io import download, unpack_zip\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Get run artifacts\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse\n",
        "import os\n",
        "\n",
        "# Mode A: local folder\n",
        "RUN_DIR = \"\"  # e.g., '/content/drive/MyDrive/rofa_runs/greedy_20240101_120000'\n",
        "\n",
        "# Mode B: direct release asset URL\n",
        "ASSET_URL = \"\"  # paste a GitHub Release asset URL to download\n",
        "\n",
        "# Optional: comparison run (greedy vs branches)\n",
        "COMPARE_RUN_DIR = \"\"\n",
        "COMPARE_ASSET_URL = \"\"\n",
        "\n",
        "def _download_and_unpack(asset_url: str) -> str:\n",
        "    runs_root = Path('runs')\n",
        "    runs_root.mkdir(exist_ok=True)\n",
        "    filename = Path(urlparse(asset_url).path).name or 'run.zip'\n",
        "    zip_path = runs_root / filename\n",
        "    download(asset_url, str(zip_path))\n",
        "    run_dir = runs_root / zip_path.stem\n",
        "    unpack_zip(str(zip_path), str(run_dir))\n",
        "    return str(run_dir)\n",
        "\n",
        "def _normalize_run_dir(run_dir: str) -> str:\n",
        "    if not run_dir:\n",
        "        return run_dir\n",
        "    summary_path = Path(run_dir) / 'summary.jsonl'\n",
        "    if summary_path.exists():\n",
        "        return run_dir\n",
        "    candidates = [p for p in Path(run_dir).iterdir() if p.is_dir()]\n",
        "    if len(candidates) == 1 and (candidates[0] / 'summary.jsonl').exists():\n",
        "        return str(candidates[0])\n",
        "    return run_dir\n",
        "\n",
        "if not RUN_DIR and ASSET_URL:\n",
        "    RUN_DIR = _download_and_unpack(ASSET_URL)\n",
        "RUN_DIR = _normalize_run_dir(RUN_DIR)\n",
        "\n",
        "if not COMPARE_RUN_DIR and COMPARE_ASSET_URL:\n",
        "    COMPARE_RUN_DIR = _download_and_unpack(COMPARE_ASSET_URL)\n",
        "COMPARE_RUN_DIR = _normalize_run_dir(COMPARE_RUN_DIR)\n",
        "\n",
        "print('Primary run:', RUN_DIR)\n",
        "if COMPARE_RUN_DIR:\n",
        "    print('Compare run:', COMPARE_RUN_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Load + parse\n",
        "if not RUN_DIR:\n",
        "    raise ValueError('Set RUN_DIR or ASSET_URL first.')\n",
        "\n",
        "df = analysis.load_summary(RUN_DIR)\n",
        "required_cols = {'gold'}\n",
        "missing = required_cols - set(df.columns)\n",
        "if missing:\n",
        "    raise ValueError(f'Missing required columns: {missing}')\n",
        "\n",
        "df_compare = None\n",
        "if COMPARE_RUN_DIR:\n",
        "    df_compare = analysis.load_summary(COMPARE_RUN_DIR)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# R1: greedy accuracy\n",
        "greedy_accuracy = None\n",
        "if 'prediction' in df.columns:\n",
        "    greedy_accuracy = analysis.accuracy_greedy(df)\n",
        "    print('Greedy accuracy:', greedy_accuracy)\n",
        "else:\n",
        "    print('Not a greedy run; skipping.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# R2: leader accuracy\n",
        "leader_accuracy = None\n",
        "if 'leader_correct' in df.columns:\n",
        "    leader_accuracy = analysis.accuracy_leader(df)\n",
        "    print('Leader accuracy:', leader_accuracy)\n",
        "else:\n",
        "    print('Not a branch run; skipping.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# R3: distribution of max_frac\n",
        "max_frac_hist = None\n",
        "if 'max_frac' in df.columns:\n",
        "    max_frac_hist = analysis.max_frac_distribution(df)\n",
        "    display(max_frac_hist)\n",
        "else:\n",
        "    print('No max_frac column; skipping.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# R4: unanimous stats\n",
        "unanimous = None\n",
        "if 'max_frac' in df.columns:\n",
        "    unanimous = analysis.unanimous_stats(df)\n",
        "    print(unanimous)\n",
        "else:\n",
        "    print('No max_frac column; skipping.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# R5: near-unanimous stats\n",
        "near_unanimous = None\n",
        "if 'max_frac' in df.columns:\n",
        "    near_unanimous = analysis.near_unanimous_stats(df, threshold=0.9)\n",
        "    print(near_unanimous)\n",
        "else:\n",
        "    print('No max_frac column; skipping.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# R6: top-2 coverage\n",
        "top2_rate = None\n",
        "if 'branch_preds' in df.columns:\n",
        "    top2_rate = analysis.top2_coverage(df)\n",
        "    print('Top-2 coverage rate:', top2_rate)\n",
        "else:\n",
        "    print('No branch predictions; skipping.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# R7: R/W/Other breakdown by max_frac bins\n",
        "rw_other = None\n",
        "if 'max_frac' in df.columns:\n",
        "    rw_other = analysis.rw_other_breakdown(df)\n",
        "    display(rw_other)\n",
        "else:\n",
        "    print('No max_frac column; skipping.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# R8: error modes (unanimous wrong)\n",
        "unanimous_wrong = None\n",
        "if 'max_frac' in df.columns:\n",
        "    unanimous_wrong = analysis.unanimous_wrong(df)\n",
        "    print('Unanimous wrong count:', len(unanimous_wrong))\n",
        "    display(unanimous_wrong.head())\n",
        "else:\n",
        "    print('No max_frac column; skipping.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# R9: majority vote does not help (greedy vs leader)\n",
        "majority_vote_gap = None\n",
        "def _identify(df):\n",
        "    if df is None:\n",
        "        return None\n",
        "    if 'prediction' in df.columns:\n",
        "        return 'greedy'\n",
        "    if 'leader_correct' in df.columns:\n",
        "        return 'branches'\n",
        "    return None\n",
        "\n",
        "role_primary = _identify(df)\n",
        "role_compare = _identify(df_compare)\n",
        "\n",
        "if role_primary == 'greedy' and role_compare == 'branches':\n",
        "    greedy_accuracy = analysis.accuracy_greedy(df)\n",
        "    leader_accuracy = analysis.accuracy_leader(df_compare)\n",
        "    majority_vote_gap = leader_accuracy - greedy_accuracy\n",
        "elif role_primary == 'branches' and role_compare == 'greedy':\n",
        "    greedy_accuracy = analysis.accuracy_greedy(df_compare)\n",
        "    leader_accuracy = analysis.accuracy_leader(df)\n",
        "    majority_vote_gap = leader_accuracy - greedy_accuracy\n",
        "\n",
        "if majority_vote_gap is None:\n",
        "    print('Provide both a greedy and a branches run to compare.')\n",
        "else:\n",
        "    print('Leader accuracy - greedy accuracy:', majority_vote_gap)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# R10: subject-wise breakdown (optional)\n",
        "subject_breakdown = None\n",
        "if 'subject_name' in df.columns:\n",
        "    accuracy_field = 'leader_correct' if 'leader_correct' in df.columns else 'is_correct'\n",
        "    subject_breakdown = analysis.subject_accuracy(df, accuracy_field=accuracy_field)\n",
        "    display(subject_breakdown.head(10))\n",
        "else:\n",
        "    print('No subject_name column; skipping.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# R11: export paper tables\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "run_id = Path(RUN_DIR).name if RUN_DIR else 'run'\n",
        "report_dir = Path('reports') / run_id\n",
        "report_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "paper_report = {\n",
        "    'greedy_accuracy': greedy_accuracy,\n",
        "    'leader_accuracy': leader_accuracy,\n",
        "    'unanimous': unanimous,\n",
        "    'near_unanimous': near_unanimous,\n",
        "    'top2_coverage': top2_rate,\n",
        "    'majority_vote_gap': majority_vote_gap,\n",
        "}\n",
        "\n",
        "with open(report_dir / 'paper_report.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(paper_report, f, indent=2)\n",
        "\n",
        "if max_frac_hist is not None:\n",
        "    max_frac_hist.to_csv(report_dir / 'max_frac_distribution.csv')\n",
        "if rw_other is not None:\n",
        "    rw_other.to_csv(report_dir / 'rw_other_breakdown.csv')\n",
        "if subject_breakdown is not None:\n",
        "    subject_breakdown.to_csv(report_dir / 'subject_accuracy.csv')\n",
        "\n",
        "print('Saved reports to', report_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add your own analysis below\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}