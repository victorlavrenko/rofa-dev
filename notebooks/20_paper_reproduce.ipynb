{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e665362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "\n",
    "from rofa.papers.from_answers_to_hypotheses import analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf8622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get run artifacts\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from rofa.core.io import download, unpack_zip\n",
    "\n",
    "# Greedy run (local folder OR release asset URL)\n",
    "run_dir_greedy = r\"G:\\My Drive\\rofa_runs\\runs\\greedy_c1548993ddf6_20260108_165715\"\n",
    "greedy_asset_url = \"\"\n",
    "\n",
    "# k-sample ensemble run (local folder OR release asset URL)\n",
    "run_dir_k_sample = r\"G:\\My Drive\\rofa_runs\\runs\\k_sample_ensemble_c1548993ddf6_20260108_203546\"\n",
    "k_sample_asset_url = \"\"\n",
    "\n",
    "def _download_and_unpack(asset_url: str) -> str:\n",
    "    runs_root = Path(\"runs\")\n",
    "    runs_root.mkdir(exist_ok=True)\n",
    "    filename = Path(urlparse(asset_url).path).name or \"run.zip\"\n",
    "    zip_path = runs_root / filename\n",
    "    download(asset_url, str(zip_path))\n",
    "    run_dir = runs_root / zip_path.stem\n",
    "    unpack_zip(str(zip_path), str(run_dir))\n",
    "    return str(run_dir)\n",
    "\n",
    "def resolve_run_input(run_dir: str, asset_url: str) -> str:\n",
    "    if run_dir:\n",
    "        return run_dir\n",
    "    if asset_url:\n",
    "        return _download_and_unpack(asset_url)\n",
    "    return \"\"\n",
    "\n",
    "run_inputs = [\n",
    "    resolve_run_input(run_dir_greedy, greedy_asset_url),\n",
    "    resolve_run_input(run_dir_k_sample, k_sample_asset_url),\n",
    "]\n",
    "run_inputs = [run_input for run_input in run_inputs if run_input]\n",
    "\n",
    "if len(run_inputs) < 2:\n",
    "    raise ValueError(\"Provide both greedy and k-sample ensemble runs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a427545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load + validate\n",
    "df_greedy, df_branches, metadata = analysis.load_paper_runs(run_inputs)\n",
    "\n",
    "required_greedy_cols = {\"gold\", \"prediction\", \"is_correct\"}\n",
    "required_branch_cols = {\"gold\", \"leader\", \"leader_correct\", \"max_frac\", \"branch_preds\"}\n",
    "\n",
    "missing_greedy = required_greedy_cols - set(df_greedy.columns)\n",
    "missing_branches = required_branch_cols - set(df_branches.columns)\n",
    "if missing_greedy:\n",
    "    raise ValueError(f\"Greedy run missing required columns: {missing_greedy}\")\n",
    "if missing_branches:\n",
    "    raise ValueError(f\"k-sample run missing required columns: {missing_branches}\")\n",
    "\n",
    "print(\"df_greedy:\", df_greedy.shape)\n",
    "print(\"df_branches:\", df_branches.shape)\n",
    "print(\"Resolved runs:\", metadata[\"resolved_runs\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4269dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R1: greedy accuracy\n",
    "df_greedy_accuracy = pd.DataFrame(\n",
    "    {\"metric\": [\"greedy_accuracy\"], \"value\": [analysis.accuracy_greedy(df_greedy)]}\n",
    ")\n",
    "df_greedy_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a41f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2: leader accuracy\n",
    "df_leader_accuracy = pd.DataFrame(\n",
    "    {\"metric\": [\"leader_accuracy\"], \"value\": [analysis.accuracy_leader(df_branches)]}\n",
    ")\n",
    "df_leader_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d255ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R3: distribution of max_frac\n",
    "df_max_frac = analysis.max_frac_distribution(df_branches).reset_index()\n",
    "df_max_frac.columns = [\"max_frac_bin\", \"count\"]\n",
    "df_max_frac\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Figure 1: accuracy vs internal consensus (max_frac_exact)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_max_frac_exact = analysis.accuracy_by_max_frac_exact(df_branches)\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(df_max_frac_exact[\"max_frac_exact\"], df_max_frac_exact[\"accuracy\"], marker=\"o\")\n",
    "ax.set_xlabel(\"max_frac_exact (leader fraction, N=10)\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Accuracy vs Internal Consensus (max_frac_exact)\")\n",
    "ax.set_ylim(0.0, 1.0)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"figure1_max_frac_exact.png\", dpi=300)\n",
    "plt.show()\n",
    "df_max_frac_exact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R4: unanimous stats\n",
    "unanimous_stats = analysis.unanimous_stats(df_branches)\n",
    "df_unanimous = pd.DataFrame([unanimous_stats])\n",
    "df_unanimous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011a3821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R5: near-unanimous stats\n",
    "near_unanimous_stats = analysis.near_unanimous_stats(df_branches, threshold=0.9)\n",
    "df_near_unanimous = pd.DataFrame([near_unanimous_stats])\n",
    "df_near_unanimous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9186f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R6: top-2 coverage\n",
    "df_top2 = analysis.compute_table_top2(df_branches)\n",
    "df_top2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755442ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R7: R/W/Other breakdown by max_frac bins\n",
    "df_rw_other = analysis.rw_other_breakdown(df_branches)\n",
    "df_rw_other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380fbaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R8: error modes (unanimous wrong)\n",
    "df_unanimous_wrong = analysis.unanimous_wrong(df_branches)\n",
    "df_unanimous_wrong.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea41f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R9: majority vote does not help (greedy vs leader)\n",
    "merge_keys = [\n",
    "    key\n",
    "    for key in [\"id\", \"index\", \"question\"]\n",
    "    if key in df_greedy.columns and key in df_branches.columns\n",
    "]\n",
    "if not merge_keys:\n",
    "    raise ValueError(\"No shared keys available to merge greedy and k-sample runs.\")\n",
    "\n",
    "df_merged = df_greedy.merge(df_branches, on=merge_keys, suffixes=(\"_greedy\", \"_branches\"))\n",
    "greedy_correct = df_merged[\"is_correct\"].fillna(False).astype(bool)\n",
    "leader_correct = df_merged[\"leader_correct\"].fillna(False).astype(bool)\n",
    "df_majority_vote = pd.DataFrame(\n",
    "    {\n",
    "        \"metric\": [\"greedy_accuracy\", \"leader_accuracy\"],\n",
    "        \"value\": [greedy_correct.mean(), leader_correct.mean()],\n",
    "    }\n",
    ")\n",
    "df_majority_vote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f6a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R10: subject-wise breakdown (optional)\n",
    "df_subject_greedy = analysis.subject_accuracy(df_greedy, accuracy_field=\"is_correct\")\n",
    "df_subject_branches = analysis.subject_accuracy(df_branches, accuracy_field=\"leader_correct\")\n",
    "df_subject_breakdown = pd.DataFrame(\n",
    "    {\n",
    "        \"greedy_accuracy\": df_subject_greedy,\n",
    "        \"leader_accuracy\": df_subject_branches,\n",
    "    }\n",
    ")\n",
    "df_subject_breakdown.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8a79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R11: export paper tables\n",
    "import json\n",
    "\n",
    "run_id = Path(metadata[\"resolved_runs\"][\"k_sample_ensemble\"]).name\n",
    "report_dir = Path(\"notebooks\") / \"reports\" / run_id\n",
    "report_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "paper_report = {\n",
    "    \"greedy_accuracy\": float(df_greedy_accuracy[\"value\"][0]),\n",
    "    \"leader_accuracy\": float(df_leader_accuracy[\"value\"][0]),\n",
    "    \"unanimous\": unanimous_stats,\n",
    "    \"near_unanimous\": near_unanimous_stats,\n",
    "    \"top2_coverage\": float(df_top2[\"value\"][0]),\n",
    "}\n",
    "\n",
    "with open(report_dir / \"paper_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(paper_report, f, indent=2)\n",
    "\n",
    "df_max_frac.to_csv(report_dir / \"max_frac_distribution.csv\", index=False)\n",
    "df_rw_other.to_csv(report_dir / \"rw_other_breakdown.csv\")\n",
    "df_subject_breakdown.to_csv(report_dir / \"subject_accuracy.csv\")\n",
    "\n",
    "print(\"Saved reports to\", report_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add your own analysis below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}