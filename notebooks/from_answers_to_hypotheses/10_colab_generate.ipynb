{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ROFA — Data Generation Notebook\n",
    "\n",
    "This notebook runs the **data generation stage** for the paper  \n",
    "*From Answers to Hypotheses: Internal Consensus and Its Limits in Large Language Models*.\n",
    "\n",
    "It executes model inference under fixed decoding settings and produces\n",
    "versioned run artifacts (JSON/JSONL) that capture:\n",
    "- per-question model outputs,\n",
    "- alternative sampled hypotheses,\n",
    "- metadata required for downstream analysis.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The outputs of this notebook are **inputs** to the analysis and reproduction\n",
    "pipeline implemented in `20_paper_reproduce.ipynb`.\n",
    "They are not required for reproducing the paper figures if you use the\n",
    "pre-generated release artifacts.\n",
    "\n",
    "## Usage modes\n",
    "\n",
    "- **Reproduce paper results (recommended):**  \n",
    "  Skip this notebook and download the released run artifacts from GitHub.\n",
    "\n",
    "- **Regenerate data (optional):**  \n",
    "  Run this notebook to regenerate model outputs, e.g. to:\n",
    "  - test alternative decoding parameters,\n",
    "  - evaluate new models,\n",
    "  - extend experiments beyond the paper.\n",
    "\n",
    "## Notes\n",
    "\n",
    "- Generation can be time- and compute-intensive.\n",
    "- Results depend on model checkpoints, decoding parameters, and random seeds.\n",
    "- This notebook is typically executed in Colab or a GPU-enabled environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"openlifescienceai/medmcqa\"\n",
    "DATASET_SPLIT = \"validation\"\n",
    "SEED = 42\n",
    "N = 300\n",
    "SUBJECTS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0 — Bootstrap\n",
    "\n",
    "# install ROFA package\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if (Path.cwd().parent.parent / \"pyproject.toml\").is_file():\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \"../..\"])\n",
    "    OUT_BASE = \"./rofa_runs\"\n",
    "else:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    OUT_BASE = \"/content/drive/MyDrive/rofa_runs\"\n",
    "    subprocess.check_call([\"git\", \"clone\", \"https://github.com/victorlavrenko/rofa\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \"rofa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Validate environment (Drive + output + model)\n",
    "from pathlib import Path\n",
    "\n",
    "from rofa.core.model import MODEL_ID, load_model_with_fallback, load_tokenizer\n",
    "\n",
    "out_base = Path(OUT_BASE)\n",
    "out_base.mkdir(parents=True, exist_ok=True)\n",
    "assert out_base.exists() and out_base.is_dir(), \"Output base not available\"\n",
    "(out_base / \"tmp_write_check.txt\").write_text(\"ok\")\n",
    "(out_base / \"tmp_write_check.txt\").unlink()\n",
    "\n",
    "tokenizer = load_tokenizer()\n",
    "model = load_model_with_fallback()\n",
    "print(f\"Model ready: {MODEL_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Create a fixed question set (IDs)\n",
    "from pathlib import Path\n",
    "\n",
    "from rofa.core.question_set import create_question_set, save_question_set\n",
    "\n",
    "question_set = create_question_set(\n",
    "    {\"dataset_name\": DATASET_NAME, \"dataset_split\": DATASET_SPLIT},\n",
    "    {\n",
    "        \"seed\": SEED,\n",
    "        \"n\": N,\n",
    "        \"subjects\": SUBJECTS,\n",
    "        \"max_per_subject\": N / SUBJECTS * 1.1 + 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "qs_dir = Path(OUT_BASE) / \"question_sets\"\n",
    "qs_dir.mkdir(parents=True, exist_ok=True)\n",
    "question_set_id = question_set.qs_id\n",
    "qs_path = qs_dir / f\"{question_set_id}.json\"\n",
    "save_question_set(question_set, str(qs_path))\n",
    "\n",
    "print(f\"Saved question set: {question_set_id} -> {qs_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — Run greedy generation (native Python call)\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "from rofa.core.runner import run_generation\n",
    "from rofa.core.schemas import GenerationConfig\n",
    "from rofa.papers.from_answers_to_hypotheses.methods import GreedyDecode\n",
    "\n",
    "run_id = f\"greedy_{question_set_id}_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}\"\n",
    "run_dir = Path(OUT_BASE) / \"runs\"\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = GenerationConfig(\n",
    "    method=\"greedy\",\n",
    "    model_id=MODEL_ID,\n",
    "    out_dir=str(run_dir),\n",
    "    run_id=run_id,\n",
    "    seed=SEED,\n",
    "    max_new_tokens=1024,\n",
    "    n=N,\n",
    "    subjects=SUBJECTS,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    dataset_split=DATASET_SPLIT,\n",
    "    question_set_path=str(qs_path),\n",
    "    progress=True,\n",
    "    heartbeat_every=10,\n",
    "    write_full_records=False,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    method_impl=GreedyDecode(),\n",
    ")\n",
    "\n",
    "run_generation(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — Run k-sample ensemble generation (branches alias)\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "from rofa.core.runner import run_generation\n",
    "from rofa.core.schemas import GenerationConfig\n",
    "from rofa.papers.from_answers_to_hypotheses.methods import BranchSamplingEnsemble\n",
    "\n",
    "run_id = (\n",
    "    f\"k_sample_ensemble_{question_set_id}_\"\n",
    "    f\"{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}\"\n",
    ")\n",
    "run_dir = Path(OUT_BASE) / \"runs\"\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = GenerationConfig(\n",
    "    method=\"k_sample_ensemble\",\n",
    "    model_id=MODEL_ID,\n",
    "    out_dir=str(run_dir),\n",
    "    run_id=run_id,\n",
    "    seed=SEED,\n",
    "    max_new_tokens=1024,\n",
    "    n=N,\n",
    "    subjects=SUBJECTS,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    dataset_split=DATASET_SPLIT,\n",
    "    question_set_path=str(qs_path),\n",
    "    n_branches=10,\n",
    "    temperature=0.8,\n",
    "    top_p=0.8,\n",
    "    top_k=50,\n",
    "    progress=True,\n",
    "    heartbeat_every=10,\n",
    "    write_full_records=True,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    method_impl=BranchSamplingEnsemble(n_branches=10, temperature=0.8, top_p=0.8, top_k=50),\n",
    ")\n",
    "\n",
    "run_generation(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Publish your run artifacts to GitHub Releases (manual)\n",
    "\n",
    "1. Open Google Drive and locate your run folder under `OUT_BASE/runs/<run_id>/`.\n",
    "2. Download the run folder as a `.zip`.\n",
    "3. Create a new GitHub Release in your repository.\n",
    "4. Upload the `.zip` as a release asset.\n",
    "5. Paste the asset URL into the analysis notebook so it can download the artifacts.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
